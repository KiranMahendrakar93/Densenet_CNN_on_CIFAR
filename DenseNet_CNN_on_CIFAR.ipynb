{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "As27_DenseNet_CNN_on_CIFAR_assignment_updated.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "ZCvqo9-0HS7E"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvpilLHijhX4"
      },
      "source": [
        "### CNN on CIFR Assignment:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8VkjhEXjkH8"
      },
      "source": [
        "1.  Please visit this link to access the state-of-art DenseNet code for reference - DenseNet - cifar10 notebook link\n",
        "2.  You need to create a copy of this and \"retrain\" this model to achieve 90+ test accuracy. \n",
        "3.  You cannot use DropOut layers.\n",
        "4.  You MUST use Image Augmentation Techniques.\n",
        "5.  You cannot use an already trained model as a beginning points, you have to initilize as your own\n",
        "6.  You cannot run the program for more than 300 Epochs, and it should be clear from your log, that you have only used 300 Epochs\n",
        "7.  You cannot use test images for training the model.\n",
        "8.  You cannot change the general architecture of DenseNet (which means you must use Dense Block, Transition and Output blocks as mentioned in the code)\n",
        "9.  You are free to change Convolution types (e.g. from 3x3 normal convolution to Depthwise Separable, etc)\n",
        "10. You cannot have more than 1 Million parameters in total\n",
        "11. You are free to move the code from Keras to Tensorflow, Pytorch, MXNET etc. \n",
        "12. You can use any optimization algorithm you need. \n",
        "13. You can checkpoint your model and retrain the model from that checkpoint so that no need of training the model from first if you lost at any epoch while training. You can directly load that model and Train from that epoch. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVIx_KIigxPV"
      },
      "source": [
        "# import keras\n",
        "# from keras.datasets import cifar10\n",
        "# from keras.models import Model, Sequential\n",
        "# from keras.layers import Dense, Dropout, Flatten, Input, AveragePooling2D, merge, Activation\n",
        "# from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "# from keras.layers import Concatenate\n",
        "# from keras.optimizers import Adam\n",
        "from tensorflow.keras import models, layers\n",
        "from tensorflow.keras.models import Model, save_model, load_model\n",
        "from tensorflow.keras.layers import BatchNormalization, Activation, Flatten\n",
        "from tensorflow.keras.optimizers import Adam, Nadam, SGD\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import math\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNHw6luQg3gc"
      },
      "source": [
        "# this part will prevent tensorflow to allocate all the avaliable GPU Memory\n",
        "# backend\n",
        "import tensorflow as tf"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJFahwe3wJ9l",
        "outputId": "fe3e25a4-e53a-4646-9fd8-a4a29917217c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "filepath = '/content/drive/My Drive/Assignments/As27_CNN on CIFAR/'"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsO_yGxcg5D8"
      },
      "source": [
        "# Hyperparameters\n",
        "batch_size = 256\n",
        "num_classes = 10\n",
        "epochs = 50\n",
        "l = 12\n",
        "num_filter = 36\n",
        "compression = 0.5"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mB7o3zu1g6eT"
      },
      "source": [
        "# Load CIFAR10 Data\n",
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "img_height, img_width, channel = X_train.shape[1],X_train.shape[2],X_train.shape[3]\n",
        "\n",
        "# convert to one hot encoing \n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes) "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lAk_Mw_5-rn",
        "outputId": "a64a209b-bfd1-45b0-8539-bb17c7b87ca2"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVkpgHsc5-rp",
        "outputId": "5b0fc6e1-6c0c-4881-d982-472fc09db91a"
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ee-sge5Kg7vr"
      },
      "source": [
        "# Dense Block\n",
        "def denseblock(input, num_filter = 12):\n",
        "    global compression\n",
        "    temp = input\n",
        "    for _ in range(l): \n",
        "        BatchNorm = layers.BatchNormalization()(temp)\n",
        "        relu = layers.Activation('relu')(BatchNorm)\n",
        "        Conv2D_3_3 = layers.Conv2D(int(num_filter*compression), (3,3), use_bias=False ,padding='same')(relu)\n",
        "        # if dropout_rate>0:\n",
        "        #     Conv2D_3_3 = layers.Dropout(dropout_rate)(Conv2D_3_3)\n",
        "        concat = layers.Concatenate(axis=-1)([temp,Conv2D_3_3])\n",
        "        \n",
        "        temp = concat\n",
        "        \n",
        "    return temp\n",
        "\n",
        "## transition Blosck\n",
        "def transition(input, num_filter = 12):\n",
        "    global compression\n",
        "    BatchNorm = layers.BatchNormalization()(input)\n",
        "    relu = layers.Activation('relu')(BatchNorm)\n",
        "    Conv2D_BottleNeck = layers.Conv2D(int(num_filter*compression), (1,1), use_bias=False ,padding='same')(relu)\n",
        "    # if dropout_rate>0:\n",
        "    #      Conv2D_BottleNeck = layers.Dropout(dropout_rate)(Conv2D_BottleNeck)\n",
        "    avg = layers.AveragePooling2D(pool_size=(2,2))(Conv2D_BottleNeck)\n",
        "    return avg\n",
        "\n",
        "#output layer\n",
        "def output_layer(input):\n",
        "    global compression\n",
        "    BatchNorm = layers.BatchNormalization()(input)\n",
        "    relu = layers.Activation('relu')(BatchNorm)\n",
        "    AvgPooling = layers.AveragePooling2D(pool_size=(2,2))(relu)\n",
        "    flat = layers.Flatten()(AvgPooling)\n",
        "    output = layers.Dense(num_classes, activation='softmax')(flat)\n",
        "    return output"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anPCpQWhhGb7"
      },
      "source": [
        "input = layers.Input(shape=(img_height, img_width, channel))\n",
        "First_Conv2D = layers.Conv2D(num_filter, (3,3), use_bias=False ,padding='same')(input)\n",
        "\n",
        "First_Block = denseblock(First_Conv2D, num_filter)\n",
        "First_Transition = transition(First_Block, num_filter)\n",
        "\n",
        "Second_Block = denseblock(First_Transition, num_filter)\n",
        "Second_Transition = transition(Second_Block, num_filter)\n",
        "\n",
        "Third_Block = denseblock(Second_Transition, num_filter)\n",
        "Third_Transition = transition(Third_Block, num_filter)\n",
        "\n",
        "Last_Block = denseblock(Third_Transition,  num_filter)\n",
        "output = output_layer(Last_Block)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "c5Wksy8z5-rw",
        "outputId": "f7e8ca62-5e72-4d5e-e741-edfe88cfde83"
      },
      "source": [
        "#https://arxiv.org/pdf/1608.06993.pdf\n",
        "from IPython.display import IFrame, YouTubeVideo\n",
        "YouTubeVideo(id='-W6y8xnd--U', width=600)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/jpeg": "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\n",
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"600\"\n",
              "            height=\"300\"\n",
              "            src=\"https://www.youtube.com/embed/-W6y8xnd--U\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.YouTubeVideo at 0x7f844c8b1898>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kFh7pdxhNtT",
        "scrolled": true,
        "outputId": "34820999-933f-44d5-b064-87f872feba00"
      },
      "source": [
        "model = Model(inputs=[input], outputs=[output])\n",
        "model.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 32, 32, 36)   972         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 32, 32, 36)   144         conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 32, 32, 36)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 32, 32, 18)   5832        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 32, 32, 54)   0           conv2d[0][0]                     \n",
            "                                                                 conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 32, 32, 54)   216         concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 32, 32, 54)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 32, 32, 18)   8748        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 32, 32, 72)   0           concatenate[0][0]                \n",
            "                                                                 conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 32, 32, 72)   288         concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 32, 32, 72)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 32, 32, 18)   11664       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 32, 32, 90)   0           concatenate_1[0][0]              \n",
            "                                                                 conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 32, 32, 90)   360         concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 32, 32, 90)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 32, 32, 18)   14580       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 32, 32, 108)  0           concatenate_2[0][0]              \n",
            "                                                                 conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 32, 32, 108)  432         concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 32, 32, 108)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 32, 32, 18)   17496       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 32, 32, 126)  0           concatenate_3[0][0]              \n",
            "                                                                 conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 32, 32, 126)  504         concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 32, 32, 126)  0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 32, 32, 18)   20412       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 32, 32, 144)  0           concatenate_4[0][0]              \n",
            "                                                                 conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 32, 32, 144)  576         concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 32, 32, 144)  0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 32, 32, 18)   23328       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 32, 32, 162)  0           concatenate_5[0][0]              \n",
            "                                                                 conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 32, 32, 162)  648         concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 32, 32, 162)  0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 32, 32, 18)   26244       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 32, 32, 180)  0           concatenate_6[0][0]              \n",
            "                                                                 conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 32, 32, 180)  720         concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 32, 32, 180)  0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 32, 32, 18)   29160       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 32, 32, 198)  0           concatenate_7[0][0]              \n",
            "                                                                 conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 32, 32, 198)  792         concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 32, 32, 198)  0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 32, 32, 18)   32076       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 32, 32, 216)  0           concatenate_8[0][0]              \n",
            "                                                                 conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 32, 32, 216)  864         concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 32, 32, 216)  0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 32, 32, 18)   34992       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_10 (Concatenate)    (None, 32, 32, 234)  0           concatenate_9[0][0]              \n",
            "                                                                 conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 32, 32, 234)  936         concatenate_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 32, 32, 234)  0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 32, 32, 18)   37908       activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_11 (Concatenate)    (None, 32, 32, 252)  0           concatenate_10[0][0]             \n",
            "                                                                 conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 32, 32, 252)  1008        concatenate_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 32, 32, 252)  0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 32, 32, 18)   4536        activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 18)   0           conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 18)   72          average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 18)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 18)   2916        activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_12 (Concatenate)    (None, 16, 16, 36)   0           average_pooling2d[0][0]          \n",
            "                                                                 conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 36)   144         concatenate_12[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 36)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 18)   5832        activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_13 (Concatenate)    (None, 16, 16, 54)   0           concatenate_12[0][0]             \n",
            "                                                                 conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 54)   216         concatenate_13[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 54)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 18)   8748        activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_14 (Concatenate)    (None, 16, 16, 72)   0           concatenate_13[0][0]             \n",
            "                                                                 conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 72)   288         concatenate_14[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 72)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 18)   11664       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_15 (Concatenate)    (None, 16, 16, 90)   0           concatenate_14[0][0]             \n",
            "                                                                 conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 90)   360         concatenate_15[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 90)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 18)   14580       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_16 (Concatenate)    (None, 16, 16, 108)  0           concatenate_15[0][0]             \n",
            "                                                                 conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 108)  432         concatenate_16[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 108)  0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 18)   17496       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_17 (Concatenate)    (None, 16, 16, 126)  0           concatenate_16[0][0]             \n",
            "                                                                 conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 126)  504         concatenate_17[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 126)  0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 18)   20412       activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_18 (Concatenate)    (None, 16, 16, 144)  0           concatenate_17[0][0]             \n",
            "                                                                 conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 144)  576         concatenate_18[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 144)  0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 18)   23328       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_19 (Concatenate)    (None, 16, 16, 162)  0           concatenate_18[0][0]             \n",
            "                                                                 conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 162)  648         concatenate_19[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 162)  0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 18)   26244       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_20 (Concatenate)    (None, 16, 16, 180)  0           concatenate_19[0][0]             \n",
            "                                                                 conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 180)  720         concatenate_20[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 180)  0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 18)   29160       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_21 (Concatenate)    (None, 16, 16, 198)  0           concatenate_20[0][0]             \n",
            "                                                                 conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 198)  792         concatenate_21[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 198)  0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 18)   32076       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_22 (Concatenate)    (None, 16, 16, 216)  0           concatenate_21[0][0]             \n",
            "                                                                 conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 216)  864         concatenate_22[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 216)  0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 18)   34992       activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_23 (Concatenate)    (None, 16, 16, 234)  0           concatenate_22[0][0]             \n",
            "                                                                 conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 234)  936         concatenate_23[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 234)  0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 16, 16, 18)   4212        activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 8, 8, 18)     0           conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 8, 8, 18)     72          average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 8, 8, 18)     0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 8, 8, 18)     2916        activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_24 (Concatenate)    (None, 8, 8, 36)     0           average_pooling2d_1[0][0]        \n",
            "                                                                 conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 8, 8, 36)     144         concatenate_24[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 8, 8, 36)     0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 8, 8, 18)     5832        activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_25 (Concatenate)    (None, 8, 8, 54)     0           concatenate_24[0][0]             \n",
            "                                                                 conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 8, 8, 54)     216         concatenate_25[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 8, 8, 54)     0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 8, 8, 18)     8748        activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_26 (Concatenate)    (None, 8, 8, 72)     0           concatenate_25[0][0]             \n",
            "                                                                 conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 8, 8, 72)     288         concatenate_26[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 8, 8, 72)     0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 8, 8, 18)     11664       activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_27 (Concatenate)    (None, 8, 8, 90)     0           concatenate_26[0][0]             \n",
            "                                                                 conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 8, 8, 90)     360         concatenate_27[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 8, 8, 90)     0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 8, 8, 18)     14580       activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_28 (Concatenate)    (None, 8, 8, 108)    0           concatenate_27[0][0]             \n",
            "                                                                 conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 8, 8, 108)    432         concatenate_28[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 8, 8, 108)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 8, 8, 18)     17496       activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_29 (Concatenate)    (None, 8, 8, 126)    0           concatenate_28[0][0]             \n",
            "                                                                 conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 8, 8, 126)    504         concatenate_29[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 8, 8, 126)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 8, 8, 18)     20412       activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_30 (Concatenate)    (None, 8, 8, 144)    0           concatenate_29[0][0]             \n",
            "                                                                 conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 8, 8, 144)    576         concatenate_30[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 8, 8, 144)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 8, 8, 18)     23328       activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_31 (Concatenate)    (None, 8, 8, 162)    0           concatenate_30[0][0]             \n",
            "                                                                 conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 8, 8, 162)    648         concatenate_31[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 8, 8, 162)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 8, 8, 18)     26244       activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_32 (Concatenate)    (None, 8, 8, 180)    0           concatenate_31[0][0]             \n",
            "                                                                 conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 8, 8, 180)    720         concatenate_32[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 8, 8, 180)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 8, 8, 18)     29160       activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_33 (Concatenate)    (None, 8, 8, 198)    0           concatenate_32[0][0]             \n",
            "                                                                 conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 8, 8, 198)    792         concatenate_33[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 8, 8, 198)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 8, 8, 18)     32076       activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_34 (Concatenate)    (None, 8, 8, 216)    0           concatenate_33[0][0]             \n",
            "                                                                 conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 8, 8, 216)    864         concatenate_34[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 8, 8, 216)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 8, 8, 18)     34992       activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_35 (Concatenate)    (None, 8, 8, 234)    0           concatenate_34[0][0]             \n",
            "                                                                 conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 8, 8, 234)    936         concatenate_35[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 8, 8, 234)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 8, 8, 18)     4212        activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 4, 4, 18)     0           conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 4, 4, 18)     72          average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 4, 4, 18)     0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 4, 4, 18)     2916        activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_36 (Concatenate)    (None, 4, 4, 36)     0           average_pooling2d_2[0][0]        \n",
            "                                                                 conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 4, 4, 36)     144         concatenate_36[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 4, 4, 36)     0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 4, 4, 18)     5832        activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_37 (Concatenate)    (None, 4, 4, 54)     0           concatenate_36[0][0]             \n",
            "                                                                 conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 4, 4, 54)     216         concatenate_37[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 4, 4, 54)     0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 4, 4, 18)     8748        activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_38 (Concatenate)    (None, 4, 4, 72)     0           concatenate_37[0][0]             \n",
            "                                                                 conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 4, 4, 72)     288         concatenate_38[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 4, 4, 72)     0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 4, 4, 18)     11664       activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_39 (Concatenate)    (None, 4, 4, 90)     0           concatenate_38[0][0]             \n",
            "                                                                 conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 4, 4, 90)     360         concatenate_39[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 4, 4, 90)     0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 4, 4, 18)     14580       activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_40 (Concatenate)    (None, 4, 4, 108)    0           concatenate_39[0][0]             \n",
            "                                                                 conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 4, 4, 108)    432         concatenate_40[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 4, 4, 108)    0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 4, 4, 18)     17496       activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_41 (Concatenate)    (None, 4, 4, 126)    0           concatenate_40[0][0]             \n",
            "                                                                 conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 4, 4, 126)    504         concatenate_41[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 4, 4, 126)    0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 4, 4, 18)     20412       activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_42 (Concatenate)    (None, 4, 4, 144)    0           concatenate_41[0][0]             \n",
            "                                                                 conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 4, 4, 144)    576         concatenate_42[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 4, 4, 144)    0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 4, 4, 18)     23328       activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_43 (Concatenate)    (None, 4, 4, 162)    0           concatenate_42[0][0]             \n",
            "                                                                 conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 4, 4, 162)    648         concatenate_43[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 4, 4, 162)    0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 4, 4, 18)     26244       activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_44 (Concatenate)    (None, 4, 4, 180)    0           concatenate_43[0][0]             \n",
            "                                                                 conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 4, 4, 180)    720         concatenate_44[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 4, 4, 180)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 4, 4, 18)     29160       activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_45 (Concatenate)    (None, 4, 4, 198)    0           concatenate_44[0][0]             \n",
            "                                                                 conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 4, 4, 198)    792         concatenate_45[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 4, 4, 198)    0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 4, 4, 18)     32076       activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_46 (Concatenate)    (None, 4, 4, 216)    0           concatenate_45[0][0]             \n",
            "                                                                 conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 4, 4, 216)    864         concatenate_46[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 4, 4, 216)    0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 4, 4, 18)     34992       activation_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_47 (Concatenate)    (None, 4, 4, 234)    0           concatenate_46[0][0]             \n",
            "                                                                 conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 4, 4, 234)    936         concatenate_47[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 4, 4, 234)    0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 2, 2, 234)    0           activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 936)          0           average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           9370        flatten[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 995,230\n",
            "Trainable params: 981,658\n",
            "Non-trainable params: 13,572\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Aqzk9AFXb1y",
        "outputId": "a3bbbcbd-636d-4549-9397-65e193373259"
      },
      "source": [
        "print(len(model.layers))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "211\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4XOsW3ahSkL"
      },
      "source": [
        "# determine Loss function and Optimizer\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwT6bixU_tMv"
      },
      "source": [
        "# https://keras.io/api/preprocessing/image/#imagedatagenerator-class\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    brightness_range=[0.2,1],\n",
        "    shear_range=0.15,\n",
        "    zoom_range=0.2,\n",
        "    fill_mode=\"nearest\",\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.2,\n",
        "    )\n",
        "\n",
        "datagen.fit(X_train)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "crhGk7kEhXAz",
        "scrolled": true,
        "outputId": "f550e970-7b96-4c31-a9b1-190e70a47949"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "model.fit(datagen.flow(X_train, y_train, batch_size=batch_size, subset='training'),\n",
        "          validation_data= datagen.flow(X_train, y_train, batch_size=batch_size, subset='validation'),\n",
        "          epochs=epochs, verbose=1)\n",
        "\n",
        "save_model(model, filepath+'model_ckpt/epoch50.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "157/157 [==============================] - 122s 508ms/step - loss: 1.7343 - accuracy: 0.3650 - val_loss: 1.6979 - val_accuracy: 0.3720\n",
            "Epoch 2/50\n",
            "157/157 [==============================] - 77s 491ms/step - loss: 1.3655 - accuracy: 0.5080 - val_loss: 1.8256 - val_accuracy: 0.3791\n",
            "Epoch 3/50\n",
            "157/157 [==============================] - 79s 499ms/step - loss: 1.1542 - accuracy: 0.5868 - val_loss: 1.4568 - val_accuracy: 0.4867\n",
            "Epoch 4/50\n",
            "157/157 [==============================] - 79s 500ms/step - loss: 1.0214 - accuracy: 0.6365 - val_loss: 1.1243 - val_accuracy: 0.6116\n",
            "Epoch 5/50\n",
            "157/157 [==============================] - 79s 501ms/step - loss: 0.9151 - accuracy: 0.6749 - val_loss: 0.9605 - val_accuracy: 0.6637\n",
            "Epoch 6/50\n",
            "157/157 [==============================] - 79s 501ms/step - loss: 0.8348 - accuracy: 0.7053 - val_loss: 0.9411 - val_accuracy: 0.6706\n",
            "Epoch 7/50\n",
            "157/157 [==============================] - 79s 500ms/step - loss: 0.7770 - accuracy: 0.7257 - val_loss: 1.0944 - val_accuracy: 0.6282\n",
            "Epoch 8/50\n",
            "157/157 [==============================] - 79s 501ms/step - loss: 0.7166 - accuracy: 0.7490 - val_loss: 1.0771 - val_accuracy: 0.6524\n",
            "Epoch 9/50\n",
            "157/157 [==============================] - 79s 500ms/step - loss: 0.6812 - accuracy: 0.7600 - val_loss: 0.8464 - val_accuracy: 0.7045\n",
            "Epoch 10/50\n",
            "157/157 [==============================] - 79s 500ms/step - loss: 0.6433 - accuracy: 0.7749 - val_loss: 0.7884 - val_accuracy: 0.7327\n",
            "Epoch 11/50\n",
            "157/157 [==============================] - 79s 500ms/step - loss: 0.6215 - accuracy: 0.7814 - val_loss: 0.9540 - val_accuracy: 0.6929\n",
            "Epoch 12/50\n",
            "157/157 [==============================] - 79s 501ms/step - loss: 0.5921 - accuracy: 0.7921 - val_loss: 0.7481 - val_accuracy: 0.7428\n",
            "Epoch 13/50\n",
            "157/157 [==============================] - 79s 500ms/step - loss: 0.5657 - accuracy: 0.8006 - val_loss: 0.9802 - val_accuracy: 0.6871\n",
            "Epoch 14/50\n",
            "157/157 [==============================] - 79s 500ms/step - loss: 0.5558 - accuracy: 0.8047 - val_loss: 0.7506 - val_accuracy: 0.7509\n",
            "Epoch 15/50\n",
            "157/157 [==============================] - 79s 500ms/step - loss: 0.5266 - accuracy: 0.8165 - val_loss: 0.7458 - val_accuracy: 0.7518\n",
            "Epoch 16/50\n",
            "157/157 [==============================] - 79s 501ms/step - loss: 0.5102 - accuracy: 0.8207 - val_loss: 0.6027 - val_accuracy: 0.7928\n",
            "Epoch 17/50\n",
            "157/157 [==============================] - 79s 500ms/step - loss: 0.4978 - accuracy: 0.8285 - val_loss: 0.6614 - val_accuracy: 0.7776\n",
            "Epoch 18/50\n",
            "157/157 [==============================] - 79s 500ms/step - loss: 0.4851 - accuracy: 0.8307 - val_loss: 0.5981 - val_accuracy: 0.7965\n",
            "Epoch 19/50\n",
            "157/157 [==============================] - 79s 500ms/step - loss: 0.4609 - accuracy: 0.8386 - val_loss: 0.6010 - val_accuracy: 0.7930\n",
            "Epoch 20/50\n",
            "157/157 [==============================] - 79s 500ms/step - loss: 0.4538 - accuracy: 0.8405 - val_loss: 0.6312 - val_accuracy: 0.7911\n",
            "Epoch 21/50\n",
            "157/157 [==============================] - 79s 500ms/step - loss: 0.4483 - accuracy: 0.8424 - val_loss: 0.6596 - val_accuracy: 0.7805\n",
            "Epoch 22/50\n",
            "157/157 [==============================] - 79s 500ms/step - loss: 0.4327 - accuracy: 0.8496 - val_loss: 0.5904 - val_accuracy: 0.7934\n",
            "Epoch 23/50\n",
            "157/157 [==============================] - 79s 500ms/step - loss: 0.4230 - accuracy: 0.8538 - val_loss: 0.5987 - val_accuracy: 0.7992\n",
            "Epoch 24/50\n",
            "157/157 [==============================] - 78s 499ms/step - loss: 0.4121 - accuracy: 0.8565 - val_loss: 0.5921 - val_accuracy: 0.7978\n",
            "Epoch 25/50\n",
            "157/157 [==============================] - 79s 499ms/step - loss: 0.3965 - accuracy: 0.8593 - val_loss: 0.6853 - val_accuracy: 0.7756\n",
            "Epoch 26/50\n",
            "157/157 [==============================] - 78s 499ms/step - loss: 0.3961 - accuracy: 0.8617 - val_loss: 0.6393 - val_accuracy: 0.7814\n",
            "Epoch 27/50\n",
            "157/157 [==============================] - 79s 500ms/step - loss: 0.3866 - accuracy: 0.8652 - val_loss: 0.6354 - val_accuracy: 0.7894\n",
            "Epoch 28/50\n",
            "157/157 [==============================] - 79s 500ms/step - loss: 0.3724 - accuracy: 0.8683 - val_loss: 0.5158 - val_accuracy: 0.8208\n",
            "Epoch 29/50\n",
            "157/157 [==============================] - 78s 499ms/step - loss: 0.3700 - accuracy: 0.8713 - val_loss: 0.6694 - val_accuracy: 0.7796\n",
            "Epoch 30/50\n",
            "157/157 [==============================] - 78s 499ms/step - loss: 0.3589 - accuracy: 0.8740 - val_loss: 0.5656 - val_accuracy: 0.8126\n",
            "Epoch 31/50\n",
            "157/157 [==============================] - 78s 499ms/step - loss: 0.3481 - accuracy: 0.8778 - val_loss: 0.4962 - val_accuracy: 0.8339\n",
            "Epoch 32/50\n",
            "157/157 [==============================] - 79s 500ms/step - loss: 0.3438 - accuracy: 0.8794 - val_loss: 0.4885 - val_accuracy: 0.8372\n",
            "Epoch 33/50\n",
            "157/157 [==============================] - 78s 499ms/step - loss: 0.3426 - accuracy: 0.8795 - val_loss: 0.5953 - val_accuracy: 0.8035\n",
            "Epoch 34/50\n",
            "157/157 [==============================] - 79s 500ms/step - loss: 0.3294 - accuracy: 0.8854 - val_loss: 0.4897 - val_accuracy: 0.8347\n",
            "Epoch 35/50\n",
            "157/157 [==============================] - 78s 499ms/step - loss: 0.3253 - accuracy: 0.8864 - val_loss: 0.5455 - val_accuracy: 0.8241\n",
            "Epoch 36/50\n",
            "157/157 [==============================] - 79s 500ms/step - loss: 0.3193 - accuracy: 0.8887 - val_loss: 0.4690 - val_accuracy: 0.8403\n",
            "Epoch 37/50\n",
            "157/157 [==============================] - 79s 500ms/step - loss: 0.3114 - accuracy: 0.8913 - val_loss: 0.5200 - val_accuracy: 0.8315\n",
            "Epoch 38/50\n",
            "157/157 [==============================] - 78s 499ms/step - loss: 0.3079 - accuracy: 0.8928 - val_loss: 0.4858 - val_accuracy: 0.8392\n",
            "Epoch 39/50\n",
            "157/157 [==============================] - 78s 499ms/step - loss: 0.2959 - accuracy: 0.8964 - val_loss: 0.4841 - val_accuracy: 0.8439\n",
            "Epoch 40/50\n",
            "157/157 [==============================] - 79s 500ms/step - loss: 0.2919 - accuracy: 0.8981 - val_loss: 0.5837 - val_accuracy: 0.8148\n",
            "Epoch 41/50\n",
            "157/157 [==============================] - 78s 499ms/step - loss: 0.2924 - accuracy: 0.8971 - val_loss: 0.4974 - val_accuracy: 0.8325\n",
            "Epoch 42/50\n",
            "157/157 [==============================] - 78s 499ms/step - loss: 0.2897 - accuracy: 0.8972 - val_loss: 0.5116 - val_accuracy: 0.8312\n",
            "Epoch 43/50\n",
            "157/157 [==============================] - 79s 500ms/step - loss: 0.2787 - accuracy: 0.9027 - val_loss: 0.5452 - val_accuracy: 0.8280\n",
            "Epoch 44/50\n",
            "157/157 [==============================] - 78s 499ms/step - loss: 0.2730 - accuracy: 0.9069 - val_loss: 0.4540 - val_accuracy: 0.8533\n",
            "Epoch 45/50\n",
            "157/157 [==============================] - 78s 499ms/step - loss: 0.2721 - accuracy: 0.9035 - val_loss: 0.5035 - val_accuracy: 0.8367\n",
            "Epoch 46/50\n",
            "157/157 [==============================] - 79s 500ms/step - loss: 0.2651 - accuracy: 0.9063 - val_loss: 0.5043 - val_accuracy: 0.8399\n",
            "Epoch 47/50\n",
            "157/157 [==============================] - 78s 499ms/step - loss: 0.2614 - accuracy: 0.9086 - val_loss: 0.5109 - val_accuracy: 0.8333\n",
            "Epoch 48/50\n",
            "157/157 [==============================] - 78s 499ms/step - loss: 0.2537 - accuracy: 0.9105 - val_loss: 0.4650 - val_accuracy: 0.8452\n",
            "Epoch 49/50\n",
            "157/157 [==============================] - 78s 499ms/step - loss: 0.2590 - accuracy: 0.9099 - val_loss: 0.5834 - val_accuracy: 0.8201\n",
            "Epoch 50/50\n",
            "157/157 [==============================] - 78s 499ms/step - loss: 0.2525 - accuracy: 0.9120 - val_loss: 0.4863 - val_accuracy: 0.8458\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1DXD8TuJeH4"
      },
      "source": [
        "# https://keras.io/api/callbacks/model_checkpoint/#:~:text=Callback%20to%20save%20the%20Keras,training%20from%20the%20state%20saved.\n",
        "checkpoint_path = filepath +'model_ckpt/model_weights-{epoch:02d}-{val_accuracy:.4f}.h5'\n",
        "model_checkpoint = ModelCheckpoint(\n",
        "    filepath=checkpoint_path,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7HsR_ZG8zwE",
        "outputId": "b374ae21-44c5-46bb-ca2c-9938579d6778"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "model = load_model(filepath+'model_ckpt/epoch50.h5')\n",
        "\n",
        "model.fit(datagen.flow(X_train, y_train, batch_size=64, subset='training'),\n",
        "          validation_data= datagen.flow(X_train, y_train, batch_size=64, subset='validation'),\n",
        "          epochs=epochs, verbose=1, callbacks=[model_checkpoint, early_stopping])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "625/625 [==============================] - 121s 136ms/step - loss: 0.4625 - accuracy: 0.8411 - val_loss: 0.6715 - val_accuracy: 0.7827\n",
            "Epoch 2/50\n",
            "625/625 [==============================] - 84s 134ms/step - loss: 0.3886 - accuracy: 0.8643 - val_loss: 0.6135 - val_accuracy: 0.7968\n",
            "Epoch 3/50\n",
            "625/625 [==============================] - 84s 134ms/step - loss: 0.3608 - accuracy: 0.8759 - val_loss: 0.5220 - val_accuracy: 0.8237\n",
            "Epoch 4/50\n",
            "625/625 [==============================] - 84s 134ms/step - loss: 0.3427 - accuracy: 0.8788 - val_loss: 0.6065 - val_accuracy: 0.8030\n",
            "Epoch 5/50\n",
            "625/625 [==============================] - 84s 134ms/step - loss: 0.3325 - accuracy: 0.8853 - val_loss: 0.5770 - val_accuracy: 0.8189\n",
            "Epoch 6/50\n",
            "625/625 [==============================] - 84s 134ms/step - loss: 0.3261 - accuracy: 0.8867 - val_loss: 0.4851 - val_accuracy: 0.8411\n",
            "Epoch 7/50\n",
            "625/625 [==============================] - 84s 134ms/step - loss: 0.3179 - accuracy: 0.8891 - val_loss: 0.4414 - val_accuracy: 0.8505\n",
            "Epoch 8/50\n",
            "625/625 [==============================] - 84s 134ms/step - loss: 0.3113 - accuracy: 0.8903 - val_loss: 0.5975 - val_accuracy: 0.8140\n",
            "Epoch 9/50\n",
            "625/625 [==============================] - 84s 134ms/step - loss: 0.2971 - accuracy: 0.8952 - val_loss: 0.5865 - val_accuracy: 0.8196\n",
            "Epoch 10/50\n",
            "625/625 [==============================] - 84s 134ms/step - loss: 0.2889 - accuracy: 0.8985 - val_loss: 0.4745 - val_accuracy: 0.8452\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6fba265fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n81kn98eQFmC"
      },
      "source": [
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "lrop = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvArbkHBP4I0",
        "outputId": "67e4a1ad-3038-4fc9-aef8-8e09649930b9"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "# Weights loaded from 11th epoch of previous run\n",
        "model = load_model(filepath+'model_ckpt/model_weights-07-0.8505.h5')\n",
        "\n",
        "model.fit(datagen.flow(X_train, y_train, batch_size=64, subset='training'),\n",
        "          validation_data= datagen.flow(X_train, y_train, batch_size=64, subset='validation'),\n",
        "          epochs=epochs, verbose=1, callbacks=[model_checkpoint, early_stopping, lrop])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "625/625 [==============================] - 93s 137ms/step - loss: 0.3121 - accuracy: 0.8926 - val_loss: 0.6814 - val_accuracy: 0.7897\n",
            "Epoch 2/50\n",
            "625/625 [==============================] - 84s 134ms/step - loss: 0.3035 - accuracy: 0.8942 - val_loss: 0.4778 - val_accuracy: 0.8410\n",
            "Epoch 3/50\n",
            "625/625 [==============================] - 84s 134ms/step - loss: 0.2936 - accuracy: 0.8964 - val_loss: 0.4859 - val_accuracy: 0.8397\n",
            "Epoch 4/50\n",
            "625/625 [==============================] - 84s 134ms/step - loss: 0.2929 - accuracy: 0.8970 - val_loss: 0.4861 - val_accuracy: 0.8421\n",
            "Epoch 5/50\n",
            "625/625 [==============================] - 84s 134ms/step - loss: 0.2200 - accuracy: 0.9223 - val_loss: 0.3260 - val_accuracy: 0.8888\n",
            "Epoch 6/50\n",
            "625/625 [==============================] - 84s 134ms/step - loss: 0.1924 - accuracy: 0.9324 - val_loss: 0.3122 - val_accuracy: 0.8963\n",
            "Epoch 7/50\n",
            "625/625 [==============================] - 84s 134ms/step - loss: 0.1808 - accuracy: 0.9359 - val_loss: 0.3080 - val_accuracy: 0.8926\n",
            "Epoch 8/50\n",
            "625/625 [==============================] - 84s 134ms/step - loss: 0.1752 - accuracy: 0.9390 - val_loss: 0.3212 - val_accuracy: 0.8958\n",
            "Epoch 9/50\n",
            "625/625 [==============================] - 84s 134ms/step - loss: 0.1692 - accuracy: 0.9412 - val_loss: 0.3155 - val_accuracy: 0.8945\n",
            "Epoch 10/50\n",
            "625/625 [==============================] - 84s 134ms/step - loss: 0.1606 - accuracy: 0.9432 - val_loss: 0.3021 - val_accuracy: 0.9030\n",
            "Epoch 11/50\n",
            "625/625 [==============================] - 84s 134ms/step - loss: 0.1576 - accuracy: 0.9455 - val_loss: 0.3111 - val_accuracy: 0.8998\n",
            "Epoch 12/50\n",
            "625/625 [==============================] - 84s 134ms/step - loss: 0.1574 - accuracy: 0.9458 - val_loss: 0.2981 - val_accuracy: 0.9014\n",
            "Epoch 13/50\n",
            "625/625 [==============================] - 84s 134ms/step - loss: 0.1558 - accuracy: 0.9458 - val_loss: 0.3055 - val_accuracy: 0.8976\n",
            "Epoch 14/50\n",
            "625/625 [==============================] - 84s 134ms/step - loss: 0.1586 - accuracy: 0.9445 - val_loss: 0.3118 - val_accuracy: 0.8974\n",
            "Epoch 15/50\n",
            "625/625 [==============================] - 84s 134ms/step - loss: 0.1538 - accuracy: 0.9464 - val_loss: 0.3093 - val_accuracy: 0.8995\n",
            "Epoch 16/50\n",
            "625/625 [==============================] - 84s 134ms/step - loss: 0.1533 - accuracy: 0.9453 - val_loss: 0.3180 - val_accuracy: 0.8991\n",
            "Epoch 17/50\n",
            "625/625 [==============================] - 84s 134ms/step - loss: 0.1549 - accuracy: 0.9463 - val_loss: 0.3029 - val_accuracy: 0.9012\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb060456550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CheXW2vMB-5m"
      },
      "source": [
        "Best val_accuracy as of now is 0.9030 from previous run (10th epoch)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLdrqrurBznn",
        "outputId": "fdb3b1f7-9ed3-4122-f387-68af4973821b"
      },
      "source": [
        "early_stopping = EarlyStopping(monitor='val_accuracy', patience=5)\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "# Weights loaded from 11th epoch of previous run\n",
        "model = load_model(filepath+'model_ckpt/model_weights-10-0.9030.h5')\n",
        "\n",
        "model.fit(datagen.flow(X_train, y_train, batch_size=64, subset='training'),\n",
        "          validation_data= datagen.flow(X_train, y_train, batch_size=64, subset='validation'),\n",
        "          epochs=epochs, verbose=1, callbacks=[model_checkpoint, early_stopping, lrop])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "625/625 [==============================] - 89s 137ms/step - loss: 0.1593 - accuracy: 0.9449 - val_loss: 0.3094 - val_accuracy: 0.8984\n",
            "Epoch 2/50\n",
            "625/625 [==============================] - 85s 136ms/step - loss: 0.1590 - accuracy: 0.9443 - val_loss: 0.3112 - val_accuracy: 0.9003\n",
            "Epoch 3/50\n",
            "625/625 [==============================] - 85s 135ms/step - loss: 0.1611 - accuracy: 0.9438 - val_loss: 0.2988 - val_accuracy: 0.9012\n",
            "Epoch 4/50\n",
            "625/625 [==============================] - 85s 136ms/step - loss: 0.1585 - accuracy: 0.9460 - val_loss: 0.3134 - val_accuracy: 0.8990\n",
            "Epoch 5/50\n",
            "625/625 [==============================] - 85s 136ms/step - loss: 0.1525 - accuracy: 0.9477 - val_loss: 0.3030 - val_accuracy: 0.9024\n",
            "Epoch 6/50\n",
            "625/625 [==============================] - 85s 135ms/step - loss: 0.1513 - accuracy: 0.9474 - val_loss: 0.3131 - val_accuracy: 0.9003\n",
            "Epoch 7/50\n",
            "625/625 [==============================] - 85s 135ms/step - loss: 0.1544 - accuracy: 0.9477 - val_loss: 0.3075 - val_accuracy: 0.8975\n",
            "Epoch 8/50\n",
            "625/625 [==============================] - 85s 135ms/step - loss: 0.1522 - accuracy: 0.9470 - val_loss: 0.3024 - val_accuracy: 0.8999\n",
            "Epoch 9/50\n",
            "625/625 [==============================] - 85s 135ms/step - loss: 0.1514 - accuracy: 0.9470 - val_loss: 0.3145 - val_accuracy: 0.8966\n",
            "Epoch 10/50\n",
            "625/625 [==============================] - 85s 135ms/step - loss: 0.1557 - accuracy: 0.9462 - val_loss: 0.3061 - val_accuracy: 0.9050\n",
            "Epoch 11/50\n",
            "625/625 [==============================] - 85s 135ms/step - loss: 0.1527 - accuracy: 0.9483 - val_loss: 0.3042 - val_accuracy: 0.9003\n",
            "Epoch 12/50\n",
            "625/625 [==============================] - 85s 135ms/step - loss: 0.1543 - accuracy: 0.9465 - val_loss: 0.3089 - val_accuracy: 0.9000\n",
            "Epoch 13/50\n",
            "625/625 [==============================] - 85s 135ms/step - loss: 0.1549 - accuracy: 0.9459 - val_loss: 0.3125 - val_accuracy: 0.8974\n",
            "Epoch 14/50\n",
            "625/625 [==============================] - 84s 134ms/step - loss: 0.1551 - accuracy: 0.9460 - val_loss: 0.3090 - val_accuracy: 0.8991\n",
            "Epoch 15/50\n",
            "625/625 [==============================] - 84s 134ms/step - loss: 0.1534 - accuracy: 0.9463 - val_loss: 0.3152 - val_accuracy: 0.8986\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7faed9ec9890>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJapODw3GyuP"
      },
      "source": [
        "Best val_accuracy as of now is 0.9050 (10th epoch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCvqo9-0HS7E"
      },
      "source": [
        "### Running more epochs to ensure model has convereged to global minima by further reducing batch_size to 32"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Ok9g9RX0l1F",
        "outputId": "225bcd8b-db6d-4699-9eaf-94e0b36be843"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "# Weights loaded from 11th epoch of previous run\n",
        "model = load_model(filepath+'model_ckpt/model_weights-10-0.9050.h5')\n",
        "\n",
        "model.fit(datagen.flow(X_train, y_train, batch_size=32, subset='training'),\n",
        "          validation_data= datagen.flow(X_train, y_train, batch_size=32, subset='validation'),\n",
        "          epochs=epochs, verbose=1, callbacks=[model_checkpoint, early_stopping, lrop])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "1250/1250 [==============================] - 99s 77ms/step - loss: 0.1691 - accuracy: 0.9414 - val_loss: 0.3152 - val_accuracy: 0.8982\n",
            "Epoch 2/50\n",
            "1250/1250 [==============================] - 95s 76ms/step - loss: 0.1698 - accuracy: 0.9406 - val_loss: 0.3094 - val_accuracy: 0.8967\n",
            "Epoch 3/50\n",
            "1250/1250 [==============================] - 95s 76ms/step - loss: 0.1687 - accuracy: 0.9403 - val_loss: 0.3119 - val_accuracy: 0.8998\n",
            "Epoch 4/50\n",
            "1250/1250 [==============================] - 95s 76ms/step - loss: 0.1698 - accuracy: 0.9415 - val_loss: 0.3158 - val_accuracy: 0.8993\n",
            "Epoch 5/50\n",
            "1250/1250 [==============================] - 95s 76ms/step - loss: 0.1728 - accuracy: 0.9391 - val_loss: 0.3099 - val_accuracy: 0.8984\n",
            "Epoch 6/50\n",
            "1250/1250 [==============================] - 95s 76ms/step - loss: 0.1691 - accuracy: 0.9408 - val_loss: 0.3066 - val_accuracy: 0.8995\n",
            "Epoch 7/50\n",
            "1250/1250 [==============================] - 95s 76ms/step - loss: 0.1725 - accuracy: 0.9400 - val_loss: 0.3073 - val_accuracy: 0.9012\n",
            "Epoch 8/50\n",
            "1250/1250 [==============================] - 95s 76ms/step - loss: 0.1733 - accuracy: 0.9385 - val_loss: 0.2988 - val_accuracy: 0.9013\n",
            "Epoch 9/50\n",
            "1250/1250 [==============================] - 95s 76ms/step - loss: 0.1678 - accuracy: 0.9406 - val_loss: 0.3075 - val_accuracy: 0.8990\n",
            "Epoch 10/50\n",
            "1250/1250 [==============================] - 94s 76ms/step - loss: 0.1701 - accuracy: 0.9411 - val_loss: 0.3125 - val_accuracy: 0.8973\n",
            "Epoch 11/50\n",
            "1250/1250 [==============================] - 96s 77ms/step - loss: 0.1669 - accuracy: 0.9417 - val_loss: 0.3147 - val_accuracy: 0.8966\n",
            "Epoch 12/50\n",
            "1250/1250 [==============================] - 97s 77ms/step - loss: 0.1716 - accuracy: 0.9399 - val_loss: 0.3121 - val_accuracy: 0.8973\n",
            "Epoch 13/50\n",
            "1250/1250 [==============================] - 98s 78ms/step - loss: 0.1663 - accuracy: 0.9417 - val_loss: 0.3078 - val_accuracy: 0.9012\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7faed789bfd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nD-USMDMB7u-"
      },
      "source": [
        "### Final output\n",
        "\n",
        "We can see that the best val_accuracy is 0.9050. Model seems to be converged"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZcWydmIVhZGr",
        "outputId": "ab0fb517-05f1-441a-c5e4-0f150c809344"
      },
      "source": [
        "# Test the model\n",
        "# Loaded the weights from 25th epoch of previous run\n",
        "model_final = load_model(filepath+'model_ckpt/model_weights-10-0.9050.h5')\n",
        "score = model_final.evaluate(X_test, y_test, verbose=1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 6s 18ms/step - loss: 0.3195 - accuracy: 0.9034\n",
            "Test loss: 0.319461464881897\n",
            "Test accuracy: 0.9034000039100647\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UE3lF6EH1r_L",
        "outputId": "278bb490-a043-4833-c048-a058a2645395"
      },
      "source": [
        "# Save the trained weights in to .h5 format\n",
        "model_final.save(filepath+ \"model_ckpt/DNST_model.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}